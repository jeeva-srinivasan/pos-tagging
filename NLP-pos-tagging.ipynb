{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')],\n",
       " [('Lorillard', 'NOUN'),\n",
       "  ('Inc.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('unit', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('New', 'ADJ'),\n",
       "  ('York-based', 'ADJ'),\n",
       "  ('Loews', 'NOUN'),\n",
       "  ('Corp.', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('makes', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarettes', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stopped', 'VERB'),\n",
       "  ('using', 'VERB'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Micronite', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('1956', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Although', 'ADP'),\n",
       "  ('preliminary', 'ADJ'),\n",
       "  ('findings', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('*-2', 'X'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('year', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('latest', 'ADJ'),\n",
       "  ('results', 'NOUN'),\n",
       "  ('appear', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('today', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('New', 'NOUN'),\n",
       "  ('England', 'NOUN'),\n",
       "  ('Journal', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Medicine', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('a', 'DET'),\n",
       "  ('forum', 'NOUN'),\n",
       "  ('likely', 'ADJ'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('bring', 'VERB'),\n",
       "  ('new', 'ADJ'),\n",
       "  ('attention', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('problem', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('Lorillard', 'NOUN'),\n",
       "  ('spokewoman', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('an', 'DET'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('story', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('We', 'PRON'),\n",
       "  (\"'re\", 'VERB'),\n",
       "  ('talking', 'VERB'),\n",
       "  ('about', 'ADP'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  ('before', 'ADP'),\n",
       "  ('anyone', 'NOUN'),\n",
       "  ('heard', 'VERB'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('having', 'VERB'),\n",
       "  ('any', 'DET'),\n",
       "  ('questionable', 'ADJ'),\n",
       "  ('properties', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('There', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('no', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('our', 'PRON'),\n",
       "  ('products', 'NOUN'),\n",
       "  ('now', 'ADV'),\n",
       "  ('.', '.'),\n",
       "  (\"''\", '.')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading few sentences from the dataset\n",
    "nltk_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('James', 'NOUN'), ('L.', 'NOUN'), ('Pate', 'NOUN'), (',', '.'), ('54-year-old', 'ADJ'), ('executive', 'NOUN'), ('vice', 'NOUN'), ('president', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-44', 'X'), ('a', 'DET'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('oil', 'NOUN'), ('concern', 'NOUN'), (',', '.'), ('*', 'X'), ('expanding', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('to', 'PRT'), ('14', 'NUM'), ('members', 'NOUN'), ('.', '.')], [('Garbage', 'NOUN'), ('magazine', 'NOUN'), (',', '.'), ('billed', 'VERB'), ('*', 'X'), ('as', 'ADP'), ('``', '.'), ('The', 'NOUN'), ('Practical', 'NOUN'), ('Journal', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('Environment', 'NOUN'), (',', '.'), (\"''\", '.'), ('is', 'VERB'), ('about', 'ADP'), ('*-1', 'X'), ('to', 'PRT'), ('find', 'VERB'), ('out', 'PRT'), ('0', 'X'), ('*?*', 'X'), ('.', '.')], [('December', 'NOUN'), ('delivery', 'NOUN'), ('gold', 'NOUN'), ('fell', 'VERB'), ('$', '.'), ('3.20', 'NUM'), ('*U*', 'X'), ('an', 'DET'), ('ounce', 'NOUN'), ('to', 'PRT'), ('$', '.'), ('377.60', 'NUM'), ('*U*', 'X'), ('.', '.')], [('Dell', 'NOUN'), ('Computer', 'NOUN'), ('Corp.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('cut', 'VERB'), ('prices', 'NOUN'), ('on', 'ADP'), ('several', 'ADJ'), ('of', 'ADP'), ('its', 'PRON'), ('personal', 'ADJ'), ('computer', 'NOUN'), ('lines', 'NOUN'), ('by', 'ADP'), ('5', 'NUM'), ('%', 'NOUN'), ('to', 'PRT'), ('17', 'NUM'), ('%', 'NOUN'), ('*U*', 'X'), ('.', '.')], [('A', 'DET'), ('study', 'NOUN'), ('by', 'ADP'), ('Tulane', 'NOUN'), ('Prof.', 'NOUN'), ('James', 'NOUN'), ('Wright', 'NOUN'), ('says', 'VERB'), ('0', 'X'), ('homelessness', 'NOUN'), ('is', 'VERB'), ('due', 'ADJ'), ('to', 'PRT'), ('a', 'DET'), ('complex', 'ADJ'), ('array', 'NOUN'), ('of', 'ADP'), ('problems', 'NOUN'), (',', '.'), ('with', 'ADP'), ('the', 'DET'), ('common', 'ADJ'), ('thread', 'NOUN'), ('of', 'ADP'), ('poverty', 'NOUN'), ('.', '.')], [('*', 'X'), ('Think', 'VERB'), ('about', 'ADP'), ('what', 'PRON'), ('*T*-1', 'X'), ('causes', 'VERB'), ('the', 'DET'), ('difference', 'NOUN'), ('in', 'ADP'), ('prices', 'NOUN'), ('between', 'ADP'), ('the', 'DET'), ('two', 'NUM'), ('markets', 'NOUN'), ('for', 'ADP'), ('S&P', 'NOUN'), ('500', 'NUM'), ('stocks', 'NOUN'), ('--', '.'), ('usually', 'ADV'), ('it', 'PRON'), ('is', 'VERB'), ('large', 'ADJ'), ('investors', 'NOUN'), ('initiating', 'VERB'), ('a', 'DET'), ('buy', 'NOUN'), ('or', 'CONJ'), ('sell', 'NOUN'), ('in', 'ADP'), ('Chicago', 'NOUN'), ('.', '.')], [('But', 'CONJ'), ('can', 'VERB'), ('Mr.', 'NOUN'), ('Hahn', 'NOUN'), ('carry', 'VERB'), ('it', 'PRON'), ('off', 'ADP'), ('?', '.')], [('There', 'DET'), (\"'s\", 'VERB'), ('no', 'DET'), ('culprit', 'NOUN'), ('here', 'ADV'), ('.', '.')], [('It', 'PRON'), ('signals', 'VERB'), ('Congress', 'NOUN'), (\"'s\", 'PRT'), ('attempt', 'NOUN'), (',', '.'), ('under', 'ADP'), ('the', 'DET'), ('pretext', 'NOUN'), ('of', 'ADP'), ('*', 'X'), ('guarding', 'VERB'), ('the', 'DET'), ('public', 'ADJ'), ('purse', 'NOUN'), (',', '.'), ('*', 'X'), ('to', 'PRT'), ('deny', 'VERB'), ('the', 'DET'), ('president', 'NOUN'), ('the', 'DET'), ('funding', 'NOUN'), ('necessary', 'ADJ'), ('*', 'X'), ('to', 'PRT'), ('execute', 'VERB'), ('certain', 'ADJ'), ('of', 'ADP'), ('his', 'PRON'), ('duties', 'NOUN'), ('and', 'CONJ'), ('prerogatives', 'NOUN'), ('specified', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('Article', 'NOUN'), ('II', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Constitution', 'NOUN'), ('.', '.')], [('When', 'ADV'), ('the', 'DET'), ('company', 'NOUN'), ('asked', 'VERB'), ('members', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('mailing', 'NOUN'), ('which', 'DET'), ('cars', 'NOUN'), ('they', 'PRON'), ('would', 'VERB'), ('like', 'VERB'), ('*-3', 'X'), ('to', 'PRT'), ('get', 'VERB'), ('information', 'NOUN'), ('about', 'ADP'), ('*T*-2', 'X'), ('for', 'ADP'), ('possible', 'ADJ'), ('future', 'ADJ'), ('purchases', 'NOUN'), ('*T*-1', 'X'), (',', '.'), ('Buick', 'NOUN'), ('came', 'VERB'), ('in', 'PRT'), ('fourth', 'ADJ'), ('among', 'ADP'), ('U.S.', 'NOUN'), ('cars', 'NOUN'), ('and', 'CONJ'), ('in', 'ADP'), ('the', 'DET'), ('top', 'NOUN'), ('10', 'NUM'), ('of', 'ADP'), ('all', 'DET'), ('cars', 'NOUN'), (',', '.'), ('the', 'DET'), ('spokeswoman', 'NOUN'), ('says', 'VERB'), ('0', 'X'), ('*T*-4', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test sets\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,train_size=0.95,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James',\n",
       " 'L.',\n",
       " 'Pate',\n",
       " ',',\n",
       " '54-year-old',\n",
       " 'executive',\n",
       " 'vice',\n",
       " 'president',\n",
       " ',',\n",
       " 'was']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12011\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADJ', 'ADV', '.', 'X', 'NOUN', 'DET', 'PRON', 'CONJ', 'NUM', 'PRT', 'ADP', 'VERB'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emission probabilities \n",
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transition Probabilty\n",
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.67545721e-02, 4.94478317e-03, 6.39525279e-02, 2.02736109e-02,\n",
       "        7.00016499e-01, 4.77995723e-03, 3.29652219e-04, 1.69770885e-02,\n",
       "        2.14273948e-02, 1.07136974e-02, 7.77979195e-02, 1.20323058e-02],\n",
       "       [1.26895189e-01, 7.87738934e-02, 1.35464728e-01, 2.24126559e-02,\n",
       "        3.06526031e-02, 6.85563609e-02, 1.45023074e-02, 6.26236014e-03,\n",
       "        3.23005915e-02, 1.48319053e-02, 1.20632827e-01, 3.48714560e-01],\n",
       "       [4.36547324e-02, 5.32154776e-02, 9.37133580e-02, 2.75096968e-02,\n",
       "        2.19626591e-01, 1.74258143e-01, 6.75565973e-02, 5.86272217e-02,\n",
       "        7.98232183e-02, 2.52548023e-03, 9.19996426e-02, 8.73996541e-02],\n",
       "       [1.64958369e-02, 2.62652151e-02, 1.63356826e-01, 7.46316463e-02,\n",
       "        6.27802685e-02, 5.49327359e-02, 5.57335056e-02, 9.60922521e-03,\n",
       "        2.56246002e-03, 1.82575271e-01, 1.45579755e-01, 2.05477253e-01],\n",
       "       [1.21633997e-02, 1.72925442e-02, 2.39787504e-01, 2.85766628e-02,\n",
       "        2.63638020e-01, 1.34090493e-02, 4.65286663e-03, 4.24253531e-02,\n",
       "        9.04927682e-03, 4.42205518e-02, 1.77028760e-01, 1.47755995e-01],\n",
       "       [2.05016881e-01, 1.25422096e-02, 1.79691277e-02, 4.58273031e-02,\n",
       "        6.37240708e-01, 5.18572098e-03, 3.85914138e-03, 4.82392672e-04,\n",
       "        2.21900623e-02, 2.41196336e-04, 9.52725485e-03, 3.99179943e-02],\n",
       "       [7.31800795e-02, 3.40996161e-02, 3.90804596e-02, 9.08045992e-02,\n",
       "        2.09961683e-01, 9.19540226e-03, 6.51340978e-03, 4.98084305e-03,\n",
       "        6.51340978e-03, 1.26436781e-02, 2.33716480e-02, 4.89655167e-01],\n",
       "       [1.15690865e-01, 5.57377040e-02, 3.46604213e-02, 8.89929757e-03,\n",
       "        3.48946124e-01, 1.19906321e-01, 5.94847761e-02, 4.68384067e-04,\n",
       "        4.30913344e-02, 4.68384055e-03, 5.52693196e-02, 1.53161585e-01],\n",
       "       [3.35731432e-02, 3.29736201e-03, 1.19904079e-01, 2.09832132e-01,\n",
       "        3.50719422e-01, 2.99760187e-03, 1.19904079e-03, 1.37889693e-02,\n",
       "        1.86450839e-01, 2.72781774e-02, 3.44724208e-02, 1.64868105e-02],\n",
       "       [8.71137381e-02, 9.86193307e-03, 4.30637747e-02, 1.38067063e-02,\n",
       "        2.47863248e-01, 1.02235369e-01, 1.77514795e-02, 2.30111764e-03,\n",
       "        5.65417483e-02, 1.97238661e-03, 1.97238661e-02, 3.97764623e-01],\n",
       "       [1.07264958e-01, 1.34615386e-02, 3.98504287e-02, 3.47222239e-02,\n",
       "        3.20512831e-01, 3.25534195e-01, 6.93376064e-02, 8.54700862e-04,\n",
       "        6.14316240e-02, 1.38888892e-03, 1.72008555e-02, 8.44017137e-03],\n",
       "       [6.51853010e-02, 8.23556855e-02, 3.53507884e-02, 2.17465624e-01,\n",
       "        1.11102477e-01, 1.33866832e-01, 3.55061777e-02, 5.12780668e-03,\n",
       "        2.31528245e-02, 3.12330052e-02, 9.06689465e-02, 1.68984532e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>DET</th>\n",
       "      <th>PRON</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADP</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.066755</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.063953</td>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.700016</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.077798</td>\n",
       "      <td>0.012032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADV</td>\n",
       "      <td>0.126895</td>\n",
       "      <td>0.078774</td>\n",
       "      <td>0.135465</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.068556</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.120633</td>\n",
       "      <td>0.348715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>0.043655</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>0.093713</td>\n",
       "      <td>0.027510</td>\n",
       "      <td>0.219627</td>\n",
       "      <td>0.174258</td>\n",
       "      <td>0.067557</td>\n",
       "      <td>0.058627</td>\n",
       "      <td>0.079823</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>0.163357</td>\n",
       "      <td>0.074632</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.145580</td>\n",
       "      <td>0.205477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.012163</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.239788</td>\n",
       "      <td>0.028577</td>\n",
       "      <td>0.263638</td>\n",
       "      <td>0.013409</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.042425</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.044221</td>\n",
       "      <td>0.177029</td>\n",
       "      <td>0.147756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DET</td>\n",
       "      <td>0.205017</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>0.045827</td>\n",
       "      <td>0.637241</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.039918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRON</td>\n",
       "      <td>0.073180</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>0.090805</td>\n",
       "      <td>0.209962</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.489655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CONJ</td>\n",
       "      <td>0.115691</td>\n",
       "      <td>0.055738</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.348946</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>0.059485</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.043091</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.055269</td>\n",
       "      <td>0.153162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NUM</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.119904</td>\n",
       "      <td>0.209832</td>\n",
       "      <td>0.350719</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.186451</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>0.016487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRT</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.043064</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>0.102235</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>0.397765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADP</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.034722</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.325534</td>\n",
       "      <td>0.069338</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VERB</td>\n",
       "      <td>0.065185</td>\n",
       "      <td>0.082356</td>\n",
       "      <td>0.035351</td>\n",
       "      <td>0.217466</td>\n",
       "      <td>0.111102</td>\n",
       "      <td>0.133867</td>\n",
       "      <td>0.035506</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>0.031233</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.168985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADJ       ADV         .         X      NOUN       DET      PRON  \\\n",
       "ADJ   0.066755  0.004945  0.063953  0.020274  0.700016  0.004780  0.000330   \n",
       "ADV   0.126895  0.078774  0.135465  0.022413  0.030653  0.068556  0.014502   \n",
       ".     0.043655  0.053215  0.093713  0.027510  0.219627  0.174258  0.067557   \n",
       "X     0.016496  0.026265  0.163357  0.074632  0.062780  0.054933  0.055734   \n",
       "NOUN  0.012163  0.017293  0.239788  0.028577  0.263638  0.013409  0.004653   \n",
       "DET   0.205017  0.012542  0.017969  0.045827  0.637241  0.005186  0.003859   \n",
       "PRON  0.073180  0.034100  0.039080  0.090805  0.209962  0.009195  0.006513   \n",
       "CONJ  0.115691  0.055738  0.034660  0.008899  0.348946  0.119906  0.059485   \n",
       "NUM   0.033573  0.003297  0.119904  0.209832  0.350719  0.002998  0.001199   \n",
       "PRT   0.087114  0.009862  0.043064  0.013807  0.247863  0.102235  0.017751   \n",
       "ADP   0.107265  0.013462  0.039850  0.034722  0.320513  0.325534  0.069338   \n",
       "VERB  0.065185  0.082356  0.035351  0.217466  0.111102  0.133867  0.035506   \n",
       "\n",
       "          CONJ       NUM       PRT       ADP      VERB  \n",
       "ADJ   0.016977  0.021427  0.010714  0.077798  0.012032  \n",
       "ADV   0.006262  0.032301  0.014832  0.120633  0.348715  \n",
       ".     0.058627  0.079823  0.002525  0.092000  0.087400  \n",
       "X     0.009609  0.002562  0.182575  0.145580  0.205477  \n",
       "NOUN  0.042425  0.009049  0.044221  0.177029  0.147756  \n",
       "DET   0.000482  0.022190  0.000241  0.009527  0.039918  \n",
       "PRON  0.004981  0.006513  0.012644  0.023372  0.489655  \n",
       "CONJ  0.000468  0.043091  0.004684  0.055269  0.153162  \n",
       "NUM   0.013789  0.186451  0.027278  0.034472  0.016487  \n",
       "PRT   0.002301  0.056542  0.001972  0.019724  0.397765  \n",
       "ADP   0.000855  0.061432  0.001389  0.017201  0.008440  \n",
       "VERB  0.005128  0.023153  0.031233  0.090669  0.168985  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to a data frame for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95373"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vannila Flavor\n",
    "# Viterbi Heuristic (no modifications)\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating on test set\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  738.6486480236053\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "#print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045823118989251"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vanilla = len(check)/len(tagged_seq)\n",
    "accuracy_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of incorrectly tagged words\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "len(incorrect_tagged_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 13th June 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADJ'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'ADJ'), ('.', '.'), ('Android', 'ADJ'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'ADJ'), ('worldwide', 'ADJ'), ('on', 'ADP'), ('smartphones', 'ADJ'), ('since', 'ADP'), ('2011', 'ADJ'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('13th', 'ADJ'), ('June', 'NOUN'), ('2013', 'ADJ'), ('.', '.')]\n",
      "3.826481342315674\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Viterbi Heuristic(vannila), the algorithm will choose the tag having max (emission_p * transition_p) probability. However, there are situations where algorithm can not predict the tag because the max probability is 0. In those scenarios we are going to route the alogorithm to with modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try to solve the problem of unknown words using rule based tagging (method 1)\n",
    "\n",
    "regex_pattern = [\n",
    "    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'), #words ending with 'ing' or 'ed' or 'es' like deciding, decided, decides is a verb\n",
    "    (r'.*ly$', 'ADV'),  #words ending with 'ly' like accidentally are marked as adverb\n",
    "    (r'^([0-9]|[aA-zZ])+\\-[aA-zZ]*$','ADJ'),  # words like 'best-selling', 'adorable', 'beautiful', 'fabulous' marked as adjective \n",
    "    (r'.*able$', 'ADJ'), \n",
    "    (r'.*ful$', 'ADJ'),\n",
    "    (r'.*ous$', 'ADJ'),\n",
    "    (r'^[aA-zZ].*[0-9]+','NOUN'),     # Alpha Numeric words marked as noun\n",
    "    (r'.*ness$', 'NOUN'),\n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns - words ending with 's\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'.*ers$', 'NOUN'),              # eg.- kinderganteners, government, hazeltown\n",
    "    (r'.*ment$', 'NOUN'),\n",
    "    (r'.*town$', 'NOUN'),\n",
    "    (r'^(0|([*|-|$].*))','X'), # Any special character combination\n",
    "    (r'(The|the|A|a|An|an|That|that|This|this|Those|those|These|these)$', 'DET'), # That/this/these/those belong to the category of Demonstrative determiners\n",
    "    (r'[0-9].?[,\\/]?[0-9]*','NUM'), # Numbers  \n",
    "    (r'.*', 'NOUN')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating regex pattern\n",
    "regexp_tagger = nltk.RegexpTagger(regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi heuristic Rule based  (Modified version1)\n",
    "def ViterbiRuleBased(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        #modification to route to regex tagger in case of pmax is zero\n",
    "        if pmax == 0.0:\n",
    "            dummyp = []\n",
    "            dummyp.append(word)\n",
    "            [state.append(x[1]) for x in regexp_tagger.tag(dummyp)]          \n",
    "        # getting state for which probability is maximum\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq2 = ViterbiRuleBased(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566283235904205"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "check2 = [i for i, j in zip(tagged_seq2, test_run_base) if i == j] \n",
    "accuracy_rulebased = len(check2)/len(tagged_seq2)\n",
    "accuracy_rulebased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing and evaluating with few test sentences\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 11th June 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq =  ViterbiRuleBased(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('11th', 'ADJ'), ('June', 'NOUN'), ('2013', 'NUM'), ('.', '.')]\n",
      "3.9932961463928223\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to solve the problem of unknown words lets use another technique known as lexicon based tagging with rule based as backoff\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=regexp_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi heuristic lexicon based  (Modified version2)\n",
    "def ViterbiLexiconBased(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        #modification to route to lexicon based/rule based\n",
    "        if pmax == 0.0:\n",
    "            dummyp = []\n",
    "            dummyp.append(word)\n",
    "            [state.append(x[1]) for x in lexicon_tagger.tag(dummyp)]          \n",
    "        # getting state for which probability is maximum\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq3 = ViterbiLexiconBased(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  821.1825449466705\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547425985291345"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "accuracy_lexicon_based = lexicon_tagger.evaluate(test_set)\n",
    "accuracy_lexicon_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing and evaluating with few test sentences\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 11th June 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq =  ViterbiLexiconBased(words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('11th', 'ADJ'), ('June', 'NOUN'), ('2013', 'NUM'), ('.', '.')]\n",
      "4.0856451988220215\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi heuristic noun word tag for unknown words (Modified version3)\n",
    "#lets see if a common tag given to all unknown words is better or worse than a rule based or lexicon tagger\n",
    "def ViterbiCommonTag(words, train_bag = train_tagged_words):\n",
    "    tagged_seq = Viterbi(words)\n",
    "    V = list(set([pair[0] for pair in train_bag]))\n",
    "    words_list = [pair[0] for pair in tagged_seq] #list of words in WORDS\n",
    "    Viterbi_tags = [pair[1] for pair in tagged_seq]\n",
    "    for key, word in enumerate(words_list):\n",
    "        if word not in V: #unknown word\n",
    "            Viterbi_tags[key] = 'NOUN'\n",
    "    return list(zip(words_list, Viterbi_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq4 = ViterbiCommonTag(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937205355459174"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating accuracy\n",
    "check4 = [i for i, j in zip(tagged_seq4, test_run_base) if i == j] \n",
    "accuracy_commontag = len(check4)/len(tagged_seq4)\n",
    "accuracy_commontag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('11th', 'ADJ'), ('June', 'NOUN'), ('2013', 'NOUN'), ('.', '.')]\n",
      "3.7758898735046387\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating with few test sentences\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 11th June 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq =  ViterbiCommonTag(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viterbi heuristic probablistic approach (Modified version4)\n",
    "\n",
    "def ViterbiProbabilistic(words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            #compute emission Probabilities and state Probabilities\n",
    "            if(words[key] in V):\n",
    "                emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = transition_p\n",
    "                                   \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq5 = ViterbiProbabilistic(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935319630397888"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy\n",
    "check5 = [i for i, j in zip(tagged_seq5, test_run_base) if i == j] \n",
    "accuracy_probablistic = len(check5)/len(tagged_seq5)\n",
    "accuracy_probablistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('11th', 'ADJ'), ('June', 'NOUN'), ('2013', 'NOUN'), ('.', '.')]\n",
      "3.3922619819641113\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating with few test sentences\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 11th June 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq =  ViterbiProbabilistic(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(tagged_seq)\n",
    "print(difference)\n",
    "#probablistic approch gives almost same accuracy as the common tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045823118989251"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937205355459174"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_commontag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547425985291345"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_lexicon_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566283235904205"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_rulebased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935319630397888"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_probablistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above approches, i would conclude that rule based modifications provided the best results for tagging unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADJ'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'ADJ'), ('.', '.'), ('Android', 'ADJ'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'ADJ'), ('worldwide', 'ADJ'), ('on', 'ADP'), ('smartphones', 'ADJ'), ('since', 'ADP'), ('2011', 'ADJ'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'ADJ'), ('.', '.'), ('Google', 'ADJ'), ('and', 'CONJ'), ('Twitter', 'ADJ'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'ADJ'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'ADJ'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'ADJ'), ('firehose', 'ADJ'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'ADJ'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'ADJ'), ('.', '.'), ('The', 'DET'), ('2018', 'ADJ'), ('FIFA', 'ADJ'), ('World', 'NOUN'), ('Cup', 'ADJ'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'ADJ'), ('FIFA', 'ADJ'), ('World', 'NOUN'), ('Cup', 'ADJ'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'ADJ'), ('contested', 'ADJ'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating on Vanilla Flavor\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq =  Viterbi(words)\n",
    "print(tagged_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'NOUN'), ('firehose', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating on Lexicon modifications\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq =  ViterbiLexiconBased(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'VERB'), ('firehose', 'X'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating on Probablistic modification\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq =  ViterbiProbabilistic(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'NOUN'), ('firehose', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating on Common Tag modification\n",
    "\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq =  ViterbiCommonTag(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'NOUN'), ('firehose', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#testing and evaluating on Rulebased modification\n",
    "sentence_test = 'Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq =  ViterbiRuleBased(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going ahead with rule based modification as it gave the most satisfactory results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the above examples it is evident in a few cases such as unknown words like Android, Google, Twitter, FIFA were incorrectly marked by the vanilla flavor, are now correctly marked as NOUN with rule based modification. Also dates like 21st or year 2018 was incorrectly marked by vanilla flavor, are now correctly marked as NUM, other words like tournament, contested, firehose, domineering also correctly marked after running it with modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
